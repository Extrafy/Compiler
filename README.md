# 2024编译器设计文档（持续更新中）

> 22373407  王飞阳

## 一、参考编译器介绍

暂无

## 二、编译器总体设计

暂无

## 三、词法分析设计

### 1.编码前的设计

在整个编译器项目中，词法分析属于前端部分，因此将 `Lexer` 类放至 `frontend` 文件夹下，以便于后续的项目管理。同时，新建 `Config` 类存放一些配置信息（如输入输出的文件地址，是否产生错误等），放于 `config` 文件夹下。最后，将 `Compiler` 类单独放于根目录下，用于整个编译的启动。

从整体功能上来讲，通过读取 `Config` 存放的配置信息，在 `Lexer` 类中读取文件，进行相应的词法分析操作。最后通过 `Compiler` 统一调度，将词法分析结果写到 `lexer.txt` 文件中，将相应错误信息（如若存在错误）写到 `error.txt` 文件中。

### 2.编码完成之后的修改

在编写代码过程中，发现有很多操作（如文件读写操作）是各模块都可能需要的，因此不妨将一些所有模块都常用的操作单独编写成类，放于 `utils` 文件夹下，以符合单一职责原则。词法分析部分有用于读文件和写文件的 `InputOutput` 类。同理，错误处理操作也可单独提炼出来。将所有错误处理的类放于 `error` 文件夹下，大致分为 `Error` ，`ErrorType` 和 `HandleError` 三个类。对于词法分析模块，特别的，可将 `token` 也包装成单独的类。我单独创建一个 `token` 文件夹用于存放和所有 `token` 处理相关的类，包括：`Token` ，`TokenType` 两个类。

#### 2.1 `InputOutput` IO操作处理

**设计思路**

总的来说，`InputOutput` 直接读取整个文件为字符串，将读取文件内容储存到字符串 `content` 中，提供给 `Lexer` 进行词法分析，实现了输入与源文件词法解析、源文件词法解析与词法解析的解耦。

**方法**

* `read`：读入文件内容并保存
* `write`：将字符串写入指定文件
* `write(方法重载)`：将正确的词法分析结果写入 `lexer.txt`
* `writeError`：将错误写入 `error.txt`

#### 2.2 `Token` 终结符处理

**设计思路**

使用 `Token` 类储存每次分割出来的终结符，再通过 `Lexer` 统一调用，为词法分析提供方便的服务。

**属性**

* `tokenType`：终结符的类型，是 `TokenType` 枚举类，为词法分析提供类别码之一
* `value`：所分割出来的终结符的值，以字符串进行存储
* `line`：所分割出来的终结符所在的行数，从 1 开始计算

**方法**

* `setTokenType` ，`getTokenType`：设置、获取终结符类型
* `setValue` ，`getValue`：设置、获取终结符的值
* `setLine` ，`getLine`：设置、获取终结符所在的行数
* `toString`：重写 `toString` 方法，以符合题设词法分析输出

#### 2.3 `Error` 错误

**设计思路**

和 `Token` 的设计思路类似，设计 `ErrorType` 枚举类来表示错误类型，将错误封装为 `Error` 类，为 `HandleError` 提供服务。

**属性**

* `errorType`：错误的类型，是 `ErrorType` 枚举类，为 `a -- m` 类错误之一
* `errorLine`：错误所在的行数，从 1 开始计算

**方法**

* `setErrorType` ，`getErrorType`：设置、获取终结符类型
* `setErrorLine` ，`getErrorLine`：设置、获取终结符所在的行数
* `toString`：重写 `toString` 方法，以符合题设错误输出

#### 2.4 `HandleError` 错误处理

**设计思路**

采取单例模式设计，用于添加处理所有错误信息。

**属性**

* `instance`：私有静态的单例对象
* `errorList`：储存所有错误的列表

**方法**

* `getInstance`：获取单例对象
* `getErrorList`：获取所有错误的列表，对外开放
* `addError`：添加新的错误至列表中

#### 2.5 `Lexer` 词法分析处理

**设计思路**

采取单例模式，提供 `analyse` 方法，通过 `Compiler` 传入读入的字符串 `source` ，进行词法分析，并将结果储存在 `tokenList` 中，并向外提供获取接口。

词法分析时，需要注意以下几点：

* 每次读取字符是需要判断当前索引是否已经超出 `source` 的长度，否则可能会抛出异常。
* 需要注意单行注释并不一定会以 `\n` 收尾，可能会直接到达终点。
* 在对字符常量进行词法分析时，需要考虑到转义字符。

**属性**

* `curLine`：记录词法分析时当前所在的行号
* `value`：记录每次分割出来的终结符的值，以字符串进行存储
* `tokenType`：终结符的类型，是 `TokenType` 枚举类，为词法分析提供类别码之一
* `tokenList`：所有已经分割出来的终结符的列表
* `reservedWords`：关键词的值与关键词的类别码的映射
* `instance`：私有静态的单例对象

**方法**

* `getTokenList`：获取储存所有 `token` 的列表
* `resetting`：在分割出一个终结符之后，将 `value` 和 `tokenType` 初始化，以便下一次分割
* `getInstance`：获取单例对象
* `analyse`：词法分析的关键步骤，通过循环遍历整个读入文本字符串，进行词法分析

## 四、语法分析设计

### 1.编码前的设计

在项目结构方面，语法分析属于前端内容，故将 `Parser` 类放于 `frontend` 文件夹中。此外，由于语法分析涉及到抽象语法树的建立，因此新建了一个 `AST` 文件夹，在下设置 `AST` 类，用于构建抽象语法树

#### 1.1 抽象语法树类

本部分核心设计思想为：每一个非终结符都有其对应的类/接口并对外提供方法，自己实现的优化/解耦不能取代这些类/接口。每一个非终结符都是 `AST` 类中的内部类。每一个非终结符对应的内部类中，都包含此非终结符文法推导规则中的各属性，并提供所有属性的 `get` 方法和对此非终结符类的 `print` 方法，从而方便 `Parser` 的递归调用。

特别的，对于一些特殊的非终结符，有以下的实现技巧：

* 对于 `AddExp` 等文法推导包含左递归的的非终结符，通过改写其文法，将左递归转变为右递归，使得可以使用递归下降法进行解析。考虑到改写了文法之后会引起相应语法树的改变，对于语法成分输出顺序和题目中要求的会存在差异，因此还需调整相应的输出顺序来解决。
* 对于 `Stmt` 这个文法右侧声明种类较多的非终结符，在 `Stmt` 类中定义 `StmtType` 枚举型，以区分右侧对应的各种声明，并针对右侧的不同种声明编写相应的构造方法。

#### 1.2 语法树节点解析器类

本部分的一个核心设计思想是：为每一个非终结符类设计对应的解析器方法。主要由相应非终结符文法推导中涉及的非终结符和终结符组成。在以上条件下，只需依次遍历词法分析板块得到的 `tokenList` ，由此递归构建出抽象语法树之后，再调用 `print` 方法，将语法树的后序遍历结果输出即可。 

### 2. 编码完成之后的修改

在编码过程中，发现不少部分可以封装成单独的方法，以减少代码的冗余性。

* 对于 `tokenList` 的遍历，定义了 `expect` 方法，用于将当前指针移动到下一单位，并可进行相应错误处理。

* 对于是否为 `<Exp>` 这个非终结符，其 `FIRST` 集包含的 `Token` 种类很多，可单独封装 `isExp` 函数，用于对 `<Exp>` 的判断。

#### 2.1 `AST` 语法树

**设计思路**

对于 `AST` 的主要设计思路，在前文已提及，就是将每个非终结符封装成内部类，设置相应的属性和方法，用于 `Paser` 的递归调用。

**属性**

以 `CompUnit` 类为例，根据其对应的文法规则：`CompUnit → {Decl} {FuncDef} MainFuncDef`，其属性定义如下：

* `declList`：`Decl` 类的列表，因为为大括号，`Decl` 类可能有多个
* `funcDefList`：`FuncDef` 类的列表，因为为大括号，`FuncDef` 类可能有多个
* `mainFuncDef`：`MainFuncDef` 类
* `type`：`CompUnit` 类的输出格式，为 `"<CompUnit>"`

**方法**

* `CompUnit` 类的构造方法
* 各属性的 `set` 方法
* `print`：输出方法，对于 `CompUnit` 类来说，即递归调用 `declList` 和 `funcDefList` 中所有类和`MainFuncDef` 类的 `print` 方法，最后再输出 `"<CompUnit>"`

而对于其他的非终结符，同理。

#### 2.2 `Parser`  语法分析器

**设计思路**

`Parser` 中关键在于为每个非终结符类定义相应的分析方法。父节点的类递归调用子节点的分析方法，从而完成对整个 `tokenList` 的语法分析。

**属性**

* `tokenList`：词法分析部分得到的结果，通过使用 `set` 方法赋给语法分析部分
* `idx`：当前 `tokenList` 正在分析的位置
* `curToken`：当前遍历到的 `Token`
* `ast`： 抽象语法树
* `instance`：单例模式，为 `Parser` 类的唯一实例

**方法**

* `getInstance`：获取单例对象
* `setTokenList`：为 `tokenList` 赋值
* `analyse`：递归调用分析方法，构建语法树
* `expect`：移动 `idx` ，并进行相应错误处理，防止影响后续的语法分析
* `isExp`：判断是否为 `Exp`
* 各非终结符对应的分析方法：按照相应文法推导规则，递归调用其它非终结符的分析方法或 `Token` 的 `expect` 方法

#### 2.3 `Error` 错误

`Error` 类新增 `equals` 方法，用于判断不同错误类是否相等；新增 `compare` 方法，用于定义不同错误的排序方法

#### 2.4 `HandleError` 错误处理

将之前的错误处理输出封装为 `printErrors` 方法，在输出之前先对 `errorList` 中的元素排序，以符合题目输出需求。
