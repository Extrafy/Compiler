# 2024编译器设计文档（持续更新中）

> 22373407  王飞阳

## 一、参考编译器介绍

暂无

## 二、编译器总体设计

暂无

## 三、词法分析设计

### 1.编码前的设计

在整个编译器项目中，词法分析属于前端部分，因此将 `Lexer` 类放至 `frontend` 文件夹下，以便于后续的项目管理。同时，新建 `Config` 类存放一些配置信息（如输入输出的文件地址，是否产生错误等），放于 `config` 文件夹下。最后，将 `Compiler` 类单独放于根目录下，用于整个编译的启动。

从整体功能上来讲，通过读取 `Config` 存放的配置信息，在 `Lexer` 类中读取文件，进行相应的词法分析操作。最后通过 `Compiler` 统一调度，将词法分析结果写到 `lexer.txt` 文件中，将相应错误信息（如若存在错误）写到 `error.txt` 文件中。

### 2.编码完成之后的修改

在编写代码过程中，发现有很多操作（如文件读写操作）是各模块都可能需要的，因此不妨将一些所有模块都常用的操作单独编写成类，放于 `utils` 文件夹下，以符合单一职责原则。词法分析部分有用于读文件和写文件的 `InputOutput` 类。同理，错误处理操作也可单独提炼出来。将所有错误处理的类放于 `error` 文件夹下，大致分为 `Error` ，`ErrorType` 和 `HandleError` 三个类。对于词法分析模块，特别的，可将 `token` 也包装成单独的类。我单独创建一个 `token` 文件夹用于存放和所有 `token` 处理相关的类，包括：`Token` ，`TokenType` 两个类。

#### 2.1 `InputOutput` IO操作处理

**设计思路**

总的来说，`InputOutput` 直接读取整个文件为字符串，将读取文件内容储存到字符串 `content` 中，提供给 `Lexer` 进行词法分析，实现了输入与源文件词法解析、源文件词法解析与词法解析的解耦。

**方法**

* `read`：读入文件内容并保存
* `write`：将字符串写入指定文件
* `write(方法重载)`：将正确的词法分析结果写入 `lexer.txt`
* `writeError`：将错误写入 `error.txt`

#### 2.2 `Token` 终结符处理

**设计思路**

使用 `Token` 类储存每次分割出来的终结符，再通过 `Lexer` 统一调用，为词法分析提供方便的服务。

**属性**

* `tokenType`：终结符的类型，是 `TokenType` 枚举类，为词法分析提供类别码之一
* `value`：所分割出来的终结符的值，以字符串进行存储
* `line`：所分割出来的终结符所在的行数，从 1 开始计算

**方法**

* `setTokenType` ，`getTokenType`：设置、获取终结符类型
* `setValue` ，`getValue`：设置、获取终结符的值
* `setLine` ，`getLine`：设置、获取终结符所在的行数
* `toString`：重写 `toString` 方法，以符合题设词法分析输出

#### 2.3 `Error` 错误

**设计思路**

和 `Token` 的设计思路类似，设计 `ErrorType` 枚举类来表示错误类型，将错误封装为 `Error` 类，为 `HandleError` 提供服务。

**属性**

* `errorType`：错误的类型，是 `ErrorType` 枚举类，为 `a -- m` 类错误之一
* `errorLine`：错误所在的行数，从 1 开始计算

**方法**

* `setErrorType` ，`getErrorType`：设置、获取终结符类型
* `setErrorLine` ，`getErrorLine`：设置、获取终结符所在的行数
* `toString`：重写 `toString` 方法，以符合题设错误输出

#### 2.4 `HandleError` 错误处理

**设计思路**

采取单例模式设计，用于添加处理所有错误信息。

**属性**

* `instance`：私有静态的单例对象
* `errorList`：储存所有错误的列表

**方法**

* `getInstance`：获取单例对象
* `getErrorList`：获取所有错误的列表，对外开放
* `addError`：添加新的错误至列表中

#### 2.5 `Lexer` 词法分析处理

**设计思路**

采取单例模式，提供 `analyse` 方法，通过 `Compiler` 传入读入的字符串 `source` ，进行词法分析，并将结果储存在 `tokenList` 中，并向外提供获取接口。

词法分析时，需要注意以下几点：

* 每次读取字符是需要判断当前索引是否已经超出 `source` 的长度，否则可能会抛出异常。
* 需要注意单行注释并不一定会以 `\n` 收尾，可能会直接到达终点。
* 在对字符常量进行词法分析时，需要考虑到转义字符。

**属性**

* `curLine`：记录词法分析时当前所在的行号
* `value`：记录每次分割出来的终结符的值，以字符串进行存储
* `tokenType`：终结符的类型，是 `TokenType` 枚举类，为词法分析提供类别码之一
* `tokenList`：所有已经分割出来的终结符的列表
* `reservedWords`：关键词的值与关键词的类别码的映射
* `instance`：私有静态的单例对象

**方法**

* `getTokenList`：获取储存所有 `token` 的列表
* `resetting`：在分割出一个终结符之后，将 `value` 和 `tokenType` 初始化，以便下一次分割
* `getInstance`：获取单例对象
* `analyse`：词法分析的关键步骤，通过循环遍历整个读入文本字符串，进行词法分析

